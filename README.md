# meta-wgs-ont-pipeline
Pipeline for processing and assembling metagenomic WGS ONT data

## System requirements
- Up-to-date Conda installation, recommend Mamba installation
- Packages described below
- 16 CPUs
- 128GB RAM
(May work on systems with fewer CPUs and less RAM but untested and likely slow)

## File descriptions
- snakefile: Main pipeline file. Contains directions for assembly.
- dag.png: PNG containing directed acyclic graph representation of pipeline.
- selected_samples.tsv: Premade .tsv for running SRR17913199 example
- Data for example run (200k reads subsampled from the ONT Kit 14 run produced in this paper:  https://microbiomejournal.biomedcentral.com/articles/10.1186/s40168-022-01415-8#availability-of-data-and-materials) can be found at https://www.dropbox.com/s/9hjez322jcd6na2/SRR17913199.fastq.gz?dl=0

## Usage
1. Make a local clone of the repo:
```
git clone https://github.com/efeickmann/meta-wgs-ont-pipeline.git \
&& cd meta-wgs-ont-pipeline
```

2. Create a Conda environment with the following packages: snakemake, filtlong, flye, racon, medaka (this could take a while!). If Medaka fails during the pipeline due to a package called 'bcftools', try recreating the environment by specifying the following packages: snakemake, filtlong, flye, racon, medaka, bcftools=1.15 (Recommend using Mamba. Instructions for installation at https://mamba.readthedocs.io/en/latest/). 

If this takes too long or doesn't work, you can try creating a Conda environment for each tool. First, make an environment for snakemake and ensure that it is active when you start the pipeline. Next, open snakefile in a text editor and uncomment the "conda" parameters for each rule. Finally, create Conda environments for each tool, named as specified in the snakefile. If Conda/Mamba don't work at all, you could try using pip. 

Activate the environment with ```mamba activate meta_pipe_env```

3. Open ```snakefile``` in your favorite text editor and edit the following parameters:
- RUN_DATE: The date your ONT data was produced, in the form YYYYMMDD. Used to ID the sequencing run. Use (or not) as necessary for personal organization.
- FLOW_CELL: The ID of the flowcell used for the run. Use (or not) as necessary for personal organization.
- ONT_MODEL: The chemistry, flowcell type, and basecaller used to generate your data. Should be given in the form ```r1041_min_high_g303``` for data produced with R10.4.1 chemistry on a minION flowcell and basecalled with Guppy v3.0.3 set to high accuracy basecalling. Use ```medaka medaka tools list\_models``` to view a list of all supported combinations.
- ARCHIVE_DIR: The directory containing the basecalled fastq files from your run. 
- BARCODE_FILE: A .tsv file with a list of the samples you'd like to process, along with their barcodes. Repo comes with an example file (```selected_samples.tsv```). If you use your own, it should be in the form:
```
sample   barcode
31278   barcode01
...   ...
```
- MIN_NANO_LEN: The minimum read length you'd like to keep.
- Threads: Each rule, if computationally expensive, has a 'threads' parameter. Lowering this parameter will cause rules to run more slowly and in some cases fail (e.g. flye requires >= 4 threads). Feel free to raise the number of threads used, at the cost of reduced parallelism in the case of processing multiple samples.

4. In the terminal, run ```snakemake -c[CORES]```, replacing [CORES] with however many CPUs you have available.

5. Wait.

6. Visualize your assembly quality using the .html summary file generated by QUAST.

## Construction outline:

### 1. Preprocessing with Filtlong
- Relevant parameters: MIN_NANO_LEN
- Recommend MIN_NANO_LEN > 200

### 2. Assembly using Flye

### 3. Polishing (avoiding reliance on Illumina reads) with Racon

### 4. Polishing with Medaka

### 5. (Recommended) Assessment with metaQUAST [not included]
